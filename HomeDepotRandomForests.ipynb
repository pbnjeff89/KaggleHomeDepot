{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Random Forests to Find the Relevance of Search Queries\n",
    "\n",
    "We are given a set of data which was generated by a group of people who looked through queries and decided how relevant they were to the product that some user eventually ended up on. What we know are the product UID, the query made, and the title of the product. We also do know more about the product than the title and UID because we also have access to the attributes of the product. This will be of great help because it gives us several more opportunities to create some features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = '/home/pbnjeff/Dropbox/KaggleHomeDepotData/'\n",
    "cleaned_data_path = '/home/pbnjeff/Dropbox/KaggleHomeDepotData/combined_cleaned.csv'\n",
    "\n",
    "train_path = folder + 'train.csv'\n",
    "test_path = folder + 'test.csv'\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "if os.path.exists(cleaned_data_path):\n",
    "    combined = pd.read_csv(cleaned_data_path)\n",
    "else:\n",
    "    combined = train.append(test)\n",
    "    combined = combined.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attributes = pd.read_csv('/home/pbnjeff/Dropbox/KaggleHomeDepotData/attributes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "I create some features, as I didn't have enough time to go through everything that I wanted to. To sumarize:\n",
    "\n",
    "* Percent query in product title: An obvious feature. If there are more words from the query in the title, then it should be more relevant.\n",
    "\n",
    "* There is at least one match between query and title: This might be a way to \"normalize\" the queries. If 1/10 terms match for one query and 1/9 terms match for another, the previous feature alone would say that the query with 1/9 matches is more relevant, but it's not exactly a fair comparison given that each percent match is nearly the same anyway.\n",
    "\n",
    "* Numerical string in both: People might not know the exact number, but may have gotten something close to it. Basically, it's a feature that gives an A for effort, but combined with the previous two features, gives a bonus (possibly too much) for matching numbers.\n",
    "\n",
    "* Material matches: An obvious feature if you're given the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def breakDownQueryNames(df):\n",
    "    \n",
    "    # Lowercase for everything to normalize\n",
    "    df['query_terms'] = df['search_term'].str.lower()\n",
    "    df['query_terms'] = df['search_term'].str.replace('-',' ')\n",
    "    df['productname_terms'] = df['product_title'].str.lower()\n",
    "    df['productname_terms'] = df['productname_terms'].replace('-',' ')\n",
    "    df['query_terms'] = df['query_terms'].str.split(' ')\n",
    "    df['productname_terms'] = df['productname_terms'].str.split(' ')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def removeLists(df):\n",
    "    \"\"\"\n",
    "    Helper function to remove unnecessary columns for training models\n",
    "    \"\"\"\n",
    "    \n",
    "    return df.drop(['query_terms','productname_terms','material_terms'],axis=1)\n",
    "\n",
    "def percentQueryInProductName(df):\n",
    "    \n",
    "    \n",
    "    df['percentQueryInName'] = pd.Series()\n",
    "    \n",
    "    for i in range(len(df['query_terms'])):\n",
    "\n",
    "        numQueryTerms = len(df['query_terms'][i])\n",
    "        numNameTerms = len(df['productname_terms'][i])\n",
    "        queryTermsInName = 0\n",
    "\n",
    "        for j in range(numQueryTerms):\n",
    "\n",
    "            if df['query_terms'][i][j] in df['productname_terms'][i]:\n",
    "\n",
    "                queryTermsInName += 1\n",
    "\n",
    "        df.loc[i,'percentQueryInName'] = float(queryTermsInName) / numNameTerms\n",
    "        \n",
    "        printCompleted(i, len(df['query_terms']))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def printCompleted(i, total):\n",
    "    \n",
    "    if i % 10000 == 0:\n",
    "        \n",
    "        print('{0}'.format(str(i) + '/' + str(total) + ' completed!'))\n",
    "\n",
    "def hasOneMatch(df):\n",
    "    \n",
    "    df['hasMatch'] = pd.Series()\n",
    "    \n",
    "    for i in range(len(df['query_terms'])):\n",
    "        \n",
    "        numQueryTerms = len(df['query_terms'][i])\n",
    "        queryTermInName = False\n",
    "\n",
    "        for j in range(numQueryTerms):\n",
    "\n",
    "            if df['query_terms'][i][j] in df['productname_terms'][i]:\n",
    "\n",
    "                queryTermInName = True\n",
    "\n",
    "        df.loc[i,'hasMatch'] = queryTermInName\n",
    "        \n",
    "        printCompleted(i, len(df['query_terms']))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def isNumber(string):\n",
    "    \n",
    "    try:\n",
    "        float(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def queryProductHaveNumeric(df):\n",
    "    \"\"\"\n",
    "    Humans might input the wrong number, but the intention\n",
    "    was to specify a number. This is a measure of whether\n",
    "    a human had the intention.\n",
    "    \"\"\"\n",
    "    \n",
    "    df['BothHaveNumbers'] = pd.Series()\n",
    "    \n",
    "    for i in range(len(df['query_terms'])):\n",
    "        \n",
    "        queryNumber = False\n",
    "        productNumber = False\n",
    "\n",
    "        for word in df['query_terms'][i]:\n",
    "\n",
    "            if isNumber(str(word)):\n",
    "\n",
    "                queryNumber = True\n",
    "\n",
    "        for word in df['productname_terms'][i]:\n",
    "\n",
    "            if isNumber(str(word)):\n",
    "\n",
    "                productNumber = True\n",
    "\n",
    "        if (queryNumber and productNumber):\n",
    "\n",
    "            df['BothHaveNumbers'] = True\n",
    "\n",
    "        else:\n",
    "\n",
    "            df['BothHaveNumbers'] = False\n",
    "            \n",
    "        printCompleted(i, len(df['query_terms']))\n",
    "\n",
    "    return df\n",
    "\n",
    "def materialHasMatch(df):\n",
    "    \n",
    "    df['MaterialMatch'] = pd.Series()\n",
    "    \n",
    "    for i in range(len(df['query_terms'])):\n",
    "        \n",
    "        hasMatch = False\n",
    "        \n",
    "        for term in df['query_terms'][i]:\n",
    "            \n",
    "            if term in df['material_terms'][i]:\n",
    "\n",
    "                hasMatch = True\n",
    "        \n",
    "        df['MaterialMatch'][i] = hasMatch\n",
    "        \n",
    "        printCompleted(i, len(df['query_terms']))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def percentMaterialMatched(df):\n",
    "    \n",
    "    df['percentMaterialMatched'] = pd.Series()\n",
    "\n",
    "    for i in range(len(df['query_terms'])):\n",
    "        \n",
    "        numMatches = 0\n",
    "        numMaterialTerms = len(df['material_terms'][i])\n",
    "\n",
    "        for term in df['query_terms'][i]:\n",
    "\n",
    "            if term in df['material_terms'][i]:\n",
    "\n",
    "                numMatches += 1\n",
    "\n",
    "        if numMatches > numMaterialTerms:\n",
    "            numMatches = numMaterialTerms\n",
    "\n",
    "        df['percentMaterialMatched'][i] = float(numMatches) / numMaterialTerms\n",
    "\n",
    "        printCompleted(i, len(df['query_terms']))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def getMaterials(attributes, df):\n",
    "    \n",
    "    uid_materials = attributes.loc[attributes['name'] == 'Material'].drop('name', axis=1).reset_index(drop=True)\n",
    "    \n",
    "    df['material_terms'] = pd.Series()\n",
    "    uid_materials['material_terms'] = uid_materials['value'].str.lower()\n",
    "    uid_materials['materials'] = uid_materials['material_terms'].str.split(' ')\n",
    "    uid_materials = uid_materials.drop('material_terms', axis=1)\n",
    "    \n",
    "    for i in range(len(df['product_uid'])):\n",
    "        \n",
    "        uid = df['product_uid'][i]\n",
    "        mat_df = uid_materials[uid_materials['product_uid']==uid]['materials'].to_frame()\n",
    "        \n",
    "        try:\n",
    "            material_terms = mat_df.iloc[0]['materials']\n",
    "        except IndexError:\n",
    "            material_terms = ['']\n",
    "            \n",
    "        df['material_terms'][i] = material_terms\n",
    "        \n",
    "        try:\n",
    "            if math.isnan(df['material_terms'][i]):\n",
    "                df['material_terms'][i] = ['']\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # TODO: Eliminate the parenthesis surrounding things like '(mdf)'\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined = breakDownQueryNames(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/240760 completed!\n",
      "10000/240760 completed!\n",
      "20000/240760 completed!\n",
      "30000/240760 completed!\n",
      "40000/240760 completed!\n",
      "50000/240760 completed!\n",
      "60000/240760 completed!\n",
      "70000/240760 completed!\n",
      "80000/240760 completed!\n",
      "90000/240760 completed!\n",
      "100000/240760 completed!\n",
      "110000/240760 completed!\n",
      "120000/240760 completed!\n",
      "130000/240760 completed!\n",
      "140000/240760 completed!\n",
      "150000/240760 completed!\n",
      "160000/240760 completed!\n",
      "170000/240760 completed!\n",
      "180000/240760 completed!\n",
      "190000/240760 completed!\n",
      "200000/240760 completed!\n",
      "210000/240760 completed!\n",
      "220000/240760 completed!\n",
      "230000/240760 completed!\n",
      "240000/240760 completed!\n"
     ]
    }
   ],
   "source": [
    "combined = percentQueryInProductName(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/240760 completed!\n",
      "10000/240760 completed!\n",
      "20000/240760 completed!\n",
      "30000/240760 completed!\n",
      "40000/240760 completed!\n",
      "50000/240760 completed!\n",
      "60000/240760 completed!\n",
      "70000/240760 completed!\n",
      "80000/240760 completed!\n",
      "90000/240760 completed!\n",
      "100000/240760 completed!\n",
      "110000/240760 completed!\n",
      "120000/240760 completed!\n",
      "130000/240760 completed!\n",
      "140000/240760 completed!\n",
      "150000/240760 completed!\n",
      "160000/240760 completed!\n",
      "170000/240760 completed!\n",
      "180000/240760 completed!\n",
      "190000/240760 completed!\n",
      "200000/240760 completed!\n",
      "210000/240760 completed!\n",
      "220000/240760 completed!\n",
      "230000/240760 completed!\n",
      "240000/240760 completed!\n"
     ]
    }
   ],
   "source": [
    "combined = hasOneMatch(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/240760 completed!\n",
      "10000/240760 completed!\n",
      "20000/240760 completed!\n",
      "30000/240760 completed!\n",
      "40000/240760 completed!\n",
      "50000/240760 completed!\n",
      "60000/240760 completed!\n",
      "70000/240760 completed!\n",
      "80000/240760 completed!\n",
      "90000/240760 completed!\n",
      "100000/240760 completed!\n",
      "110000/240760 completed!\n",
      "120000/240760 completed!\n",
      "130000/240760 completed!\n",
      "140000/240760 completed!\n",
      "150000/240760 completed!\n",
      "160000/240760 completed!\n",
      "170000/240760 completed!\n",
      "180000/240760 completed!\n",
      "190000/240760 completed!\n",
      "200000/240760 completed!\n",
      "210000/240760 completed!\n",
      "220000/240760 completed!\n",
      "230000/240760 completed!\n",
      "240000/240760 completed!\n"
     ]
    }
   ],
   "source": [
    "combined = queryProductHaveNumeric(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined = getMaterials(attributes, combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/240760 completed!\n",
      "10000/240760 completed!\n",
      "20000/240760 completed!\n",
      "30000/240760 completed!\n",
      "40000/240760 completed!\n",
      "50000/240760 completed!\n",
      "60000/240760 completed!\n",
      "70000/240760 completed!\n",
      "80000/240760 completed!\n",
      "90000/240760 completed!\n",
      "100000/240760 completed!\n",
      "110000/240760 completed!\n",
      "120000/240760 completed!\n",
      "130000/240760 completed!\n",
      "140000/240760 completed!\n",
      "150000/240760 completed!\n",
      "160000/240760 completed!\n",
      "170000/240760 completed!\n",
      "180000/240760 completed!\n",
      "190000/240760 completed!\n",
      "200000/240760 completed!\n",
      "210000/240760 completed!\n",
      "220000/240760 completed!\n",
      "230000/240760 completed!\n",
      "240000/240760 completed!\n"
     ]
    }
   ],
   "source": [
    "combined = materialHasMatch(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/240760 completed!\n",
      "10000/240760 completed!\n",
      "20000/240760 completed!\n",
      "30000/240760 completed!\n",
      "40000/240760 completed!\n",
      "50000/240760 completed!\n",
      "60000/240760 completed!\n",
      "70000/240760 completed!\n",
      "80000/240760 completed!\n",
      "90000/240760 completed!\n",
      "100000/240760 completed!\n",
      "110000/240760 completed!\n",
      "120000/240760 completed!\n",
      "130000/240760 completed!\n",
      "140000/240760 completed!\n",
      "150000/240760 completed!\n",
      "160000/240760 completed!\n",
      "170000/240760 completed!\n",
      "180000/240760 completed!\n",
      "190000/240760 completed!\n",
      "200000/240760 completed!\n",
      "210000/240760 completed!\n",
      "220000/240760 completed!\n",
      "230000/240760 completed!\n",
      "240000/240760 completed!\n"
     ]
    }
   ],
   "source": [
    "combined = percentMaterialMatched(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined.to_csv(cleaned_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined = removeLists(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined = combined.drop(['product_title','product_uid','search_term'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cleaned = combined[~combined['relevance'].isnull()]\n",
    "test_cleaned = combined[combined['relevance'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = train_cleaned.drop(['id','relevance'], axis=1)\n",
    "train_y = train_cleaned['relevance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = test_cleaned.drop(['id','relevance'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the relevance\n",
    "\n",
    "I don't go terribly wild here. I could have used more estimators, but time and computational power limits me right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 10, min_samples_split = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=1, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = rf.predict(test_X)\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "\n",
    "submission['id'] = test_cleaned['id']\n",
    "\n",
    "submission['relevance'] = predictions\n",
    "\n",
    "out_path = '/home/pbnjeff/Dropbox/KaggleHomeDepotData/submission.csv'\n",
    "submission.to_csv(out_path, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
